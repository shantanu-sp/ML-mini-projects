{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ib=pd.DataFrame([])\n",
    "cgmm=pd.DataFrame([])\n",
    "cgm0=pd.DataFrame([])\n",
    "\n",
    "for i in range(1,6):\n",
    "    tmpib=pd.read_csv('InsulinBolusLunchPat'+str(i)+'.csv')\n",
    "    ib[i]=tmpib.max(axis=1,skipna=True)\n",
    "    \n",
    "    tmpcgm=pd.read_csv('CGMSeriesLunchPat'+str(i)+'.csv')\n",
    "    cgmm[i]=tmpcgm.max(axis=1,skipna=True)\n",
    "    \n",
    "    cgm0[i]=pd.read_csv(\"CGMSeriesLunchPat\"+str(i)+\".csv\")['cgmSeries_25']\n",
    "    \n",
    "ib=ib.fillna(ib.mean(axis=1).T, axis=0)\n",
    "cgmm=cgmm.fillna(cgmm.mean(axis=1).T, axis=0)\n",
    "cgm0 = cgm0.fillna(cgm0.mean(axis=1).T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x):\n",
    "    if x%10!=0:\n",
    "        x=math.modf((x-40)/10)[1]+1\n",
    "    else:\n",
    "        x=math.modf((x-40)/10)[1]\n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgmm=cgmm.applymap(lambda x: quantize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm0=cgm0.applymap(lambda x: quantize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(filename,x):\n",
    "    with open(filename+'.csv','a+',newline ='') as file:\n",
    "        write = csv.writer(file) \n",
    "        for y in x:\n",
    "            write.writerows([y]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(5):\n",
    "    data_list = []\n",
    "    for i in range(33):\n",
    "        l = []\n",
    "        l.append(\"a\"+str(cgmm.values[i,c]))\n",
    "        l.append(\"b\"+str(cgm0.values[i,c]))\n",
    "        l.append(\"c\"+str(ib.values[i,c]))\n",
    "        data_list.append(l)\n",
    "    \n",
    "    te=TransactionEncoder()\n",
    "    te_arr=te.fit_transform(data_list)\n",
    "    te_df=pd.DataFrame(te_arr, columns=te.columns_)\n",
    "    \n",
    "    frequent=apriori(te_df,min_support= 0.000001,use_colnames=True)\n",
    "    frequent['length']=frequent['itemsets'].apply(lambda x: len(x))\n",
    "    \n",
    "    freq3=frequent[(frequent['length']==3)&(frequent['support']>=0.00001)]\n",
    "    freq3=freq3.sort_values('support',ascending=False)\n",
    "    \n",
    "    freq_itemsets = freq3['itemsets'][:7] \n",
    "    \n",
    "    l=[sorted(list(x)) for x in freq_itemsets]\n",
    "    w=[]\n",
    "    for x in l:\n",
    "        w.append(tuple([re.sub('[a-z]', '', y) for y in x]))\n",
    "    output('frequent_itemsets',w)\n",
    "        \n",
    "    rule_1=association_rules(frequent,metric=\"confidence\",min_threshold=0.0001)\n",
    "    rule_1[\"antecedent_len\"]=rule_1[\"antecedents\"].apply(lambda x: len(x))\n",
    "    \n",
    "    rule1_max=rule_1[(rule_1['antecedent_len']>=2)&(rule_1['confidence']>0.99)&(rule_1['lift']>1.2)]\n",
    "    rule1_max=rule1_max.sort_values('confidence',ascending=False)[:3]\n",
    "    rule1_max_antecendent=[tuple(x) for x in rule1_max['antecedents']] \n",
    "    rule1_max_consequent=[tuple(x) for x in rule1_max['consequents']]\n",
    "    \n",
    "    combine=list(zip(rule1_max_antecendent,rule1_max_consequent))\n",
    "    \n",
    "    association1=[]\n",
    "    for x in combine:\n",
    "        fin=[]\n",
    "        for y in x:\n",
    "            fin+=y\n",
    "        association1.append(fin)\n",
    "        \n",
    "    lis=[sorted(list(x)) for x in association1]\n",
    "    rule1=[]\n",
    "    for x in lis:\n",
    "        for y in x:\n",
    "            tmp=list([re.sub('[a-z]', '', y) for y in x])\n",
    "        rule1.append([\"{\"+str(tmp[0])+\",\"+str(tmp[1])+\"-->\"+str(tmp[2])+\"}\"])\n",
    "    output('bestConfidence_rule1',rule1)\n",
    "    \n",
    "    rule2_min=rule_1[(rule_1['antecedent_len']>=2)&(rule_1['confidence']<0.6)&(rule_1['lift']>1.2)]\n",
    "    rule2_min=rule2_min.sort_values('confidence',ascending=True)[:1]\n",
    "    \n",
    "    combine=list(zip(tuple(rule2_min['antecedents']),tuple(rule2_min['consequents'])))\n",
    "    \n",
    "    association2=[]\n",
    "    for x in combine:\n",
    "        fin=[]\n",
    "        for y in x:\n",
    "            fin+=y\n",
    "        association2.append(fin)\n",
    "        \n",
    "    lis=[sorted(list(x)) for x in association1]\n",
    "    rule2=[]\n",
    "    for x in lis:\n",
    "        for y in x:\n",
    "            tmp=list([re.sub('[a-z]', '', y) for y in x])\n",
    "        rule2.append([\"{\"+str(tmp[0])+\",\"+str(tmp[1])+\"-->\"+str(tmp[2])+\"}\"])\n",
    "    output('leastConfidence_rule2',rule2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
