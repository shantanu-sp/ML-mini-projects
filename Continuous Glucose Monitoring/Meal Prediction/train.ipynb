{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from scipy import fftpack as fft\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(action='ignore',category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient():\n",
    "    def __init__(self,cgm):\n",
    "        self.cgm = cgm\n",
    "        \n",
    "    def preprocess(self):\n",
    "        #drop rows with 30% of values missing\n",
    "        self.cgm=self.cgm.loc[self.cgm.isnull().mean(axis=1)<0.3,:]\n",
    "        \n",
    "        #drop last column as it has many missing values for all patients\n",
    "        self.cgm=self.cgm.iloc[:,:30]\n",
    "        \n",
    "        #reset the indices\n",
    "        self.cgm.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        #interpolate the remaining missing values\n",
    "        self.cgm.interpolate(method='polynomial',order=3,inplace=True)\n",
    "        self.cgm.bfill(inplace=True)\n",
    "        self.cgm.ffill(inplace=True)\n",
    "        self.cgm=self.cgm.astype('float64')\n",
    "        \n",
    "    def fft(self,):\n",
    "        ndarr = fft.rfft(self.cgm, n=5, axis=1)\n",
    "        df= pd.DataFrame(data=ndarr)\n",
    "        df.columns=['fft'+str(i) for i in range(1,df.shape[1]+1)]\n",
    "        return df\n",
    "        \n",
    "    def rolling_mean(self,win,olap):\n",
    "        df=self.cgm.rolling(window=win,axis=1).apply(np.mean).dropna(axis=1).iloc[:,::olap]\n",
    "        df.columns=['rm'+str(i) for i in range(1,df.shape[1]+1)]\n",
    "        return df\n",
    "    \n",
    "    def kurtosis(self,win,olap):\n",
    "        df=self.cgm.rolling(window=win,axis=1).apply(kurtosis).dropna(axis=1).iloc[:,::olap]\n",
    "        df.columns=['kt'+str(i) for i in range(1,df.shape[1]+1) ]\n",
    "        return df\n",
    "\n",
    "    def stdev(self,win,olap):\n",
    "        df=self.cgm.rolling(window=win,axis=1).apply(np.std).dropna(axis=1).iloc[:,::olap]\n",
    "        df.columns=['st'+str(i) for i in range(1,df.shape[1]+1)]\n",
    "        return df\n",
    "    \n",
    "    def featureMatrix(self):\n",
    "        self.preprocess()\n",
    "        df=pd.concat([self.fft(),self.rolling_mean(10,5),self.stdev(10,5),self.kurtosis(10,5)],axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1m=Patient(pd.read_csv('mealData1.csv'))\n",
    "p1nm=Patient(pd.read_csv('Nomeal1.csv'))\n",
    "\n",
    "p2m=Patient(pd.read_csv('mealData2.csv'))\n",
    "p2nm=Patient(pd.read_csv('Nomeal2.csv'))\n",
    "\n",
    "p3m=Patient(pd.read_csv('mealData3.csv'))\n",
    "p3nm=Patient(pd.read_csv('Nomeal3.csv'))\n",
    "\n",
    "p4m=Patient(pd.read_csv('mealData4.csv'))\n",
    "p4nm=Patient(pd.read_csv('Nomeal4.csv'))\n",
    "\n",
    "p5m=Patient(pd.read_csv('mealData5.csv'))\n",
    "p5nm=Patient(pd.read_csv('Nomeal5.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1m=p1m.featureMatrix()\n",
    "p1nm=p1nm.featureMatrix()\n",
    "\n",
    "p2m=p2m.featureMatrix()\n",
    "p2nm=p2nm.featureMatrix()\n",
    "\n",
    "p3m=p3m.featureMatrix()\n",
    "p3nm=p3nm.featureMatrix()\n",
    "\n",
    "p4m=p4m.featureMatrix()\n",
    "p4nm=p4nm.featureMatrix()\n",
    "\n",
    "p5m=p5m.featureMatrix()\n",
    "p5nm=p5nm.featureMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata=p1m.append([p1nm,p2m,p2nm,p3m,p3nm,p4m,p4nm,p5m,p5nm])\n",
    "mdata=p1m.append([p2m,p3m,p4m,p5m])\n",
    "nmdata=p1nm.append([p2nm,p3nm,p4nm,p5nm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()\n",
    "mat = stdscaler.fit_transform(alldata)\n",
    "p = PCA(n_components=5)\n",
    "p.fit(mat)\n",
    "\n",
    "filename = open('pca.pkl','wb')\n",
    "pickle.dump(p,filename)\n",
    "filename.close()\n",
    "\n",
    "mdata=pd.DataFrame(p.transform(mdata))\n",
    "nmdata=pd.DataFrame(p.transform(nmdata))\n",
    "\n",
    "mdata['label'] = 1\n",
    "nmdata['label'] = 0\n",
    "\n",
    "alldata=mdata.append(nmdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=alldata.iloc[:,:5]\n",
    "labels=alldata.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for cross validation:  0.5964907445901395\n"
     ]
    }
   ],
   "source": [
    "model=MLPClassifier(hidden_layer_sizes=(100,60),learning_rate='adaptive',random_state=7)\n",
    "results=[]\n",
    "kfold=StratifiedKFold(n_splits=10,random_state=1,shuffle=True)\n",
    "cv_results=cross_val_score(model,data,labels,cv=kfold,scoring='f1')\n",
    "results.append(cv_results)\n",
    "print(\"f1 score for cross validation: \",cv_results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 60), learning_rate='adaptive',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=7, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=open(\"model.pkl\", 'wb')\n",
    "pickle.dump(model,filename)\n",
    "filename.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedWriter name='model.pkl'>\n"
     ]
    }
   ],
   "source": [
    "print(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
