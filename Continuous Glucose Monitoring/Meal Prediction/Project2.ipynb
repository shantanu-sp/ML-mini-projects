{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from scipy import fftpack as fft\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patient():\n",
    "    def __init__(self,cgm):\n",
    "        self.cgm = cgm\n",
    "        \n",
    "    def preprocess(self):\n",
    "        #drop rows with 30% of values missing\n",
    "        self.cgm=self.cgm.loc[self.cgm.isnull().mean(axis=1)<0.3,:]\n",
    "        \n",
    "        #drop last column as it has many missing values for all patients\n",
    "        self.cgm=self.cgm.iloc[:,:30]\n",
    "        \n",
    "        #reset the indices\n",
    "        self.cgm.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        #interpolate the remaining missing values\n",
    "        self.cgm.interpolate(method='polynomial',order=3,inplace=True)\n",
    "        self.cgm.bfill(inplace=True)\n",
    "        self.cgm.ffill(inplace=True)\n",
    "        self.cgm=self.cgm.astype('float64')\n",
    "        \n",
    "    def fft(self,):\n",
    "        ndarr = fft.rfft(self.cgm, n=5, axis=1)\n",
    "        df= pd.DataFrame(data=ndarr)\n",
    "        df.columns=['fft'+str(i) for i in range(1,df.shape[1]+1)]\n",
    "        return df\n",
    "        \n",
    "    def rolling_mean(self,win,olap):\n",
    "        df=self.cgm.rolling(window=win,axis=1).apply(np.mean).dropna(axis=1).iloc[:,::olap]\n",
    "        df.columns=['rm'+str(i) for i in range(1,df.shape[1]+1)]\n",
    "        return df\n",
    "    \n",
    "    def kurtosis(self,win,olap):\n",
    "        df=self.cgm.rolling(window=win,axis=1).apply(kurtosis).dropna(axis=1).iloc[:,::olap]\n",
    "        df.columns=['kt'+str(i) for i in range(1,df.shape[1]+1) ]\n",
    "        return df\n",
    "\n",
    "    def stdev(self,win,olap):\n",
    "        df=self.cgm.rolling(window=win,axis=1).apply(np.std).dropna(axis=1).iloc[:,::olap]\n",
    "        df.columns=['st'+str(i) for i in range(1,df.shape[1]+1)]\n",
    "        return df\n",
    "    \n",
    "    def featureMatrix(self):\n",
    "        self.preprocess()\n",
    "        df=pd.concat([self.fft(),self.rolling_mean(10,5),self.stdev(10,5),self.kurtosis(10,5)],axis=1)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1m=Patient(pd.read_csv('mealData1.csv'))\n",
    "p1nm=Patient(pd.read_csv('Nomeal1.csv'))\n",
    "\n",
    "p2m=Patient(pd.read_csv('mealData2.csv'))\n",
    "p2nm=Patient(pd.read_csv('Nomeal2.csv'))\n",
    "\n",
    "p3m=Patient(pd.read_csv('mealData3.csv'))\n",
    "p3nm=Patient(pd.read_csv('Nomeal3.csv'))\n",
    "\n",
    "p3m=Patient(pd.read_csv('mealData3.csv'))\n",
    "p3nm=Patient(pd.read_csv('Nomeal3.csv'))\n",
    "\n",
    "p4m=Patient(pd.read_csv('mealData4.csv'))\n",
    "p4nm=Patient(pd.read_csv('Nomeal4.csv'))\n",
    "\n",
    "p5m=Patient(pd.read_csv('mealData5.csv'))\n",
    "p5nm=Patient(pd.read_csv('Nomeal5.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p1m=p1m.featureMatrix()\n",
    "p1nm=p1nm.featureMatrix()\n",
    "\n",
    "p2m=p2m.featureMatrix()\n",
    "p2nm=p2nm.featureMatrix()\n",
    "\n",
    "p3m=p3m.featureMatrix()\n",
    "p3nm=p3nm.featureMatrix()\n",
    "\n",
    "p4m=p4m.featureMatrix()\n",
    "p4nm=p4nm.featureMatrix()\n",
    "\n",
    "p5m=p5m.featureMatrix()\n",
    "p5nm=p5nm.featureMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata=p1m.append([p1nm,p2m,p2nm,p3m,p3nm,p4m,p4nm,p5m,p5nm])\n",
    "mdata=p1m.append([p2m,p3m,p4m,p5m])\n",
    "nmdata=p1nm.append([p2nm,p3nm,p4nm,p5nm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()\n",
    "mat = stdscaler.fit_transform(alldata)\n",
    "p = PCA(n_components=5)\n",
    "p.fit(mat)\n",
    "\n",
    "mdata=pd.DataFrame(p.transform(mdata))\n",
    "nmdata=pd.DataFrame(p.transform(nmdata))\n",
    "\n",
    "mdata['label'] = 1\n",
    "nmdata['label'] = 0\n",
    "\n",
    "alldata=mdata.append(nmdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=alldata.iloc[:,:5]\n",
    "labels=alldata.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(data, labels, test_size=0.20, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.613961 (0.107355)\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100,60),learning_rate='adaptive',random_state=7)\n",
    "results=[]\n",
    "kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='f1')\n",
    "results.append(cv_results)\n",
    "print('%f (%f)' % (cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,Y_train)\n",
    "predictions = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5053763440860215 1.0 0.6714285714285714\n"
     ]
    }
   ],
   "source": [
    "pscore = precision_score(Y_validation, predictions, average='binary')\n",
    "rscore = recall_score(Y_validation, predictions, average='binary')\n",
    "f1score = f1_score(Y_validation, predictions, average='binary')\n",
    "print(pscore,rscore,f1score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def predictclass(sample):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
